# Fire Data Processor

**Fire Data Processor** — это набор скриптов для автоматизации скачивания, обработки и архивирования данных о пожарах с использованием данных NASA FIRMS.

## Структура проекта

- **`create_cron_job.py`**: Скрипт для создания одноразового cron-задания, которое запланирует выполнение `dwnld_firms.py` через одну минуту.
- **`generate_cron.py`**: Генерирует cron-задания на основе файла passlist, а также настраивает ежедневные и еженедельные задачи.
- **`dwnld_firms.py`**: Скачивает данные о пожарах с NASA FIRMS и запускает их последующую обработку.
- **`process_data.py`**: Обрабатывает данные и вставляет их в базу данных PostgreSQL.
- **`archive_data.py`**: Архивирует данные о пожарах и перемещает их в архивные таблицы базы данных.

## Установка и настройка

1. Клонируйте репозиторий:

    ```bash
    git clone https://github.com/yourusername/fire_data_processor.git
    cd fire_data_processor
    ```

2. Настройте окружение с параметрами для базы данных и API токеном в `.env`:

    ```env
    DB_HOST=forest_monitoring_postgis_v2
    DB_NAME=geo_forestry_db
    DB_USER=postgres
    DB_PASSWORD=your_password_here
    FIRMS_API_TOKEN=your_token_here
    ```

3. Соберите и запустите Docker-контейнер:

    ```bash
    docker build -t fire_data_processor .
    docker run -d fire_data_processor
    ```

## Скрипты

### 1. `create_cron_job.py`

**Назначение**: Создает одноразовое cron-задание для первого запуска в контейнере, которое запустит скрипт `dwnld_firms.py` через одну минуту.

**Использование**: 

```bash
python3 create_cron_job.py
```

### 2. generate_cron.py

**Назначение**: Генерирует cron-задания на основе файла PassList.txt, управляет существующими cron-заданиями (обновление, удаление, добавление), а также планирует ежедневные и еженедельные задачи.

**Использование**: 

```bash
python3 generate_cron.py
```

### 3. dwnld_firms.py

**Назначение**:  Скачивает данные о пожарах с NASA FIRMS. После успешного скачивания данных запускает скрипт process_data.py для их обработки.

**Использование**: 

```bash
python3 dwnld_firms.py
```

### 4. process_data.py

**Назначение**: Обрабатывает скачанные данные и вставляет их в базу данных PostgreSQL. Определяет, находятся ли точки пожаров в пределах Казахстана, и связывает их с лесными зонами.

**Использование**: 

```bash
python3 process_data.py
```

###5. archive_data.py

**Назначение**:  Архивирует данные о пожарах, старше определенного времени отсечения, перемещая их в архивные таблицы базы данных.

```bash
python3 archive_data.py
```

## Безопасность

Перед использованием убедитесь, что:

- Все учетные данные (пароли, API-токены) вынесены в переменные окружения или файлы конфигурации.
- Используйте `.gitignore` для исключения конфиденциальных данных из системы контроля версий.

Пример `.gitignore`:

```gitignore
# Исключаем конфиденциальные данные
*.env

# Исключаем логи и временные файлы
*.log
__pycache__/
*.pyc

# Исключаем директории с данными
/DownloadedData/
/ProcessedData/
```

## Логи

Все скрипты ведут журнал выполнения в файле `/var/log/app.log`. Логи могут быть полезны для отладки и мониторинга работы скриптов.
